let cameraStream=null,cvWorker=null,videoElement=null,canvas=null,isProcessing=!1,frameCount=0;async function initializeCVProcessing(e){try{console.log("ğŸ”§ Initializing CV processing pipeline..."),console.log("ğŸ“¹ Creating video element..."),videoElement=document.createElement("video"),videoElement.srcObject=e,videoElement.autoplay=!0,videoElement.muted=!0,videoElement.playsInline=!0,console.log("ğŸ¨ Creating canvas for frame extraction..."),canvas=document.createElement("canvas"),canvas.getContext("2d",{willReadFrequently:!0}),console.log("â³ Waiting for video metadata..."),await new Promise(e=>{videoElement.onloadedmetadata=async()=>{console.log(`ğŸ“ Video dimensions: ${videoElement.videoWidth}x${videoElement.videoHeight}`),canvas.width=videoElement.videoWidth,canvas.height=videoElement.videoHeight;try{await videoElement.play(),console.log("â–¶ï¸ Video started playing successfully")}catch(e){console.warn("âš ï¸ Video autoplay failed, but this is normal in some contexts:",e)}e()}}),console.log("ğŸ‘· Creating CV worker..."),cvWorker=new Worker("/cv-worker.js"),cvWorker.onmessage=e=>{const{type:o,data:a}=e.data,t=(new Date).toISOString();switch(console.log(`ğŸ“¨ [${t}] Received message from CV worker:`,o,a),o){case"ready":console.log(`ğŸš€ [${t}] CV Worker initialized:`,a.message),cvWorker.postMessage({type:"start"}),startFrameProcessing();break;case"metrics":console.log(`ğŸ‘ï¸ [${t}] Eye metrics received:`,a),console.log(`ğŸ“¤ [${t}] Forwarding metrics to service worker...`),chrome.runtime.sendMessage({type:"EYE_METRICS",data:a});break;case"error":console.error(`âŒ [${t}] CV Worker error:`,a.error)}},cvWorker.onerror=e=>{console.error("âŒ CV Worker error:",e)},console.log("ğŸš€ Initializing worker with MediaPipe model..."),cvWorker.postMessage({type:"init",data:{modelPath:"/assets/wasm/face_landmarker.task"}}),console.log("âœ… CV processing initialized successfully")}catch(e){console.error("âŒ Failed to initialize CV processing:",e)}}function startFrameProcessing(){if(!videoElement||!canvas||!cvWorker||isProcessing)return void console.log("âš ï¸ Cannot start frame processing - missing components or already processing");console.log("ğŸ¬ Starting real-time frame processing..."),isProcessing=!0;const e=canvas.getContext("2d",{willReadFrequently:!0});!function o(){if(isProcessing&&videoElement&&!videoElement.paused&&!videoElement.ended){try{if(videoElement.readyState<2)return console.log("âš ï¸ Video not ready yet, skipping detection"),void setTimeout(o,1e3);frameCount++,frameCount%30==0&&console.log(`ğŸ” Detection active - Frame ${frameCount} processed`),e.drawImage(videoElement,0,0,canvas.width,canvas.height);const a=e.getImageData(0,0,canvas.width,canvas.height);cvWorker.postMessage({type:"process",data:{imageData:a,timestamp:performance.now()}}),e.clearRect(0,0,canvas.width,canvas.height)}catch(e){console.error("âŒ Frame processing error:",e)}setTimeout(o,67)}else console.log("â¹ï¸ Frame processing stopped")}()}async function stopCVProcessing(){isProcessing=!1,cvWorker&&(cvWorker.postMessage({type:"cleanup"}),cvWorker.terminate(),cvWorker=null),videoElement&&(videoElement.srcObject=null,videoElement=null),canvas&&(canvas.getContext("2d",{willReadFrequently:!0}).clearRect(0,0,canvas.width,canvas.height),canvas=null),console.log("CV processing stopped and cleaned up")}console.log(`ğŸ¬ [${(new Date).toISOString()}] Offscreen document message listener registered`),chrome.runtime.onMessage.addListener((e,o,a)=>{if("DOWNLOAD_FRAME"===e.type)return console.log(`ğŸ“¸ [${(new Date).toISOString()}] Processing DOWNLOAD_FRAME message in offscreen document`),(async()=>{try{if(!videoElement||!canvas)return void a({success:!1,error:"Camera not initialized"});const e=async()=>new Promise((e,o)=>{const a=()=>{videoElement.readyState>=2&&videoElement.currentTime>0?e(!0):videoElement.readyState>=2?setTimeout(a,100):setTimeout(a,200)};a(),setTimeout(()=>{o(new Error("Video failed to start playing within 5 seconds"))},5e3)});return await e(),console.log(`ğŸ“¹ Video ready: readyState=${videoElement.readyState}, currentTime=${videoElement.currentTime}, dimensions=${videoElement.videoWidth}x${videoElement.videoHeight}`),canvas.getContext("2d",{willReadFrequently:!0}).drawImage(videoElement,0,0,canvas.width,canvas.height),canvas.toBlob(e=>{if(e){const o=URL.createObjectURL(e),t=`eyezen-frame-${(new Date).toISOString().replace(/[:.]/g,"-")}.png`,s=document.createElement("a");s.href=o,s.download=t,document.body.appendChild(s),s.click(),document.body.removeChild(s),URL.revokeObjectURL(o),console.log("ğŸ“¸ Frame downloaded successfully:",t),a({success:!0,filename:t})}else a({success:!1,error:"Failed to create image blob"})},"image/png"),!0}catch(e){console.error("âŒ Failed to download frame:",e),a({success:!1,error:e.message})}})(),!0;if("REQUEST_CAMERA"===e.type)return console.log("ğŸ¥ Processing REQUEST_CAMERA message in offscreen document"),(async()=>{try{cameraStream=await navigator.mediaDevices.getUserMedia({video:!0}),globalThis.eyeZenCameraStream=cameraStream,await initializeCVProcessing(cameraStream),console.log("âœ… Camera activated successfully in offscreen document with CV processing"),a({success:!0,message:"Camera access granted"})}catch(e){console.error("Failed to access camera in offscreen document:",e);let o=e.message;"NotAllowedError"===e.name||e.message.includes("Permission denied")||e.message.includes("Permission dismissed")?o="Camera permission was denied. Please allow camera access to use eye health monitoring features.":"NotFoundError"===e.name?o="No camera found. Please connect a camera to use this feature.":"NotReadableError"===e.name&&(o="Camera is already in use by another application."),a({success:!1,error:o})}})(),!0;if("STOP_CAMERA"===e.type)return(async()=>{try{await stopCVProcessing(),cameraStream&&(cameraStream.getTracks().forEach(e=>e.stop()),cameraStream=null,globalThis.eyeZenCameraStream=null,console.log("Camera stopped in offscreen document")),a({success:!0,message:"Camera stopped"})}catch(e){console.error("Failed to stop camera:",e),a({success:!1,error:e.message})}})(),!0;if("GET_CAMERA_STATE"===e.type){const e=null!==cameraStream&&cameraStream.getTracks().some(e=>"live"===e.readyState);return a({isActive:e}),!0}}),console.log(`ğŸ¬ [${(new Date).toISOString()}] Offscreen document loaded for camera access and CV processing`);